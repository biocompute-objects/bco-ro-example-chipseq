Proceeding with single-core trimming (user-defined)
Path to Cutadapt set as: 'cutadapt' (default)
Cutadapt seems to be working fine (tested command 'cutadapt --version')
Cutadapt version: 2.10
single-core operation.
No quality encoding type selected. Assuming that the data provided uses Sanger encoded Phred scores (default)



AUTO-DETECTING ADAPTER TYPE
===========================
Attempting to auto-detect adapter type from the first 1 million sequences of the first file (>> SPT5_T15_R1_T1_1.fastq.gz <<)

Found perfect matches for the following adapter sequences:
Adapter type	Count	Sequence	Sequences analysed	Percentage
Nextera	13001	CTGTCTCTTATA	100000	13.00
Illumina	0	AGATCGGAAGAGC	100000	0.00
smallRNA	0	TGGAATTCTCGG	100000	0.00
Using Nextera adapter for trimming (count: 13001). Second best hit was Illumina (count: 0)

Writing report to 'SPT5_T15_R1_T1_1.fastq.gz_trimming_report.txt'

SUMMARISING RUN PARAMETERS
==========================
Input filename: SPT5_T15_R1_T1_1.fastq.gz
Trimming mode: paired-end
Trim Galore version: 0.6.4_dev
Cutadapt version: 2.10
Number of cores used for trimming: 1
Quality Phred score cutoff: 20
Quality encoding type selected: ASCII+33
Adapter sequence: 'CTGTCTCTTATA' (Nextera Transposase sequence; auto-detected)
Maximum trimming error rate: 0.1 (default)
Minimum required adapter overlap (stringency): 1 bp
Minimum required sequence length for both reads before a sequence pair gets removed: 20 bp
Running FastQC on the data once trimming has completed
Output file(s) will be GZIP compressed

Cutadapt seems to be fairly up-to-date (version 2.10). Setting -j 1
Writing final adapter and quality trimmed output to SPT5_T15_R1_T1_1_trimmed.fq.gz


  >>> Now performing quality (cutoff '-q 20') and adapter trimming in a single pass for the adapter sequence: 'CTGTCTCTTATA' from file SPT5_T15_R1_T1_1.fastq.gz <<< 
This is cutadapt 2.10 with Python 3.7.6
Command line parameters: -j 1 -e 0.1 -q 20 -O 1 -a CTGTCTCTTATA SPT5_T15_R1_T1_1.fastq.gz
Processing reads on 1 core in single-end mode ...
Finished in 3.15 s (31 us/read; 1.91 M reads/minute).

=== Summary ===

Total reads processed:                 100,000
Reads with adapters:                    42,617 (42.6%)
Reads written (passing filters):       100,000 (100.0%)

Total basepairs processed:     7,600,000 bp
Quality-trimmed:                  18,408 bp (0.2%)
Total written (filtered):      7,185,337 bp (94.5%)

=== Adapter 1 ===

Sequence: CTGTCTCTTATA; Type: regular 3'; Length: 12; Trimmed: 42617 times

No. of allowed errors:
0-9 bp: 0; 10-12 bp: 1

Bases preceding removed adapters:
  A: 19.6%
  C: 30.8%
  G: 24.3%
  T: 25.4%
  none/other: 0.0%

Overview of removed sequences
length	count	expect	max.err	error counts
1	18027	25000.0	0	18027
2	5263	6250.0	0	5263
3	1510	1562.5	0	1510
4	770	390.6	0	770
5	598	97.7	0	598
6	568	24.4	0	568
7	547	6.1	0	547
8	548	1.5	0	548
9	543	0.4	0	542 1
10	510	0.1	1	499 11
11	489	0.0	1	481 8
12	505	0.0	1	496 9
13	493	0.0	1	485 8
14	470	0.0	1	459 11
15	537	0.0	1	527 10
16	513	0.0	1	503 10
17	594	0.0	1	584 10
18	541	0.0	1	532 9
19	517	0.0	1	512 5
20	542	0.0	1	531 11
21	498	0.0	1	486 12
22	584	0.0	1	576 8
23	416	0.0	1	410 6
24	469	0.0	1	461 8
25	451	0.0	1	443 8
26	537	0.0	1	523 14
27	561	0.0	1	553 8
28	391	0.0	1	385 6
29	490	0.0	1	481 9
30	458	0.0	1	454 4
31	410	0.0	1	395 15
32	553	0.0	1	545 8
33	329	0.0	1	322 7
34	417	0.0	1	414 3
35	315	0.0	1	309 6
36	276	0.0	1	272 4
37	333	0.0	1	324 9
38	313	0.0	1	306 7
39	283	0.0	1	279 4
40	179	0.0	1	174 5
41	74	0.0	1	73 1
42	63	0.0	1	62 1
43	17	0.0	1	16 1
44	9	0.0	1	9
45	21	0.0	1	21
46	10	0.0	1	8 2
47	19	0.0	1	19
48	21	0.0	1	21
49	15	0.0	1	15
50	5	0.0	1	4 1
53	1	0.0	1	0 1
55	1	0.0	1	0 1
59	1	0.0	1	1
65	3	0.0	1	0 3
67	1	0.0	1	0 1
68	6	0.0	1	0 6
69	1	0.0	1	0 1
74	1	0.0	1	0 1

RUN STATISTICS FOR INPUT FILE: SPT5_T15_R1_T1_1.fastq.gz
=============================================
100000 sequences processed in total
The length threshold of paired-end sequences gets evaluated later on (in the validation step)

Writing report to 'SPT5_T15_R1_T1_2.fastq.gz_trimming_report.txt'

SUMMARISING RUN PARAMETERS
==========================
Input filename: SPT5_T15_R1_T1_2.fastq.gz
Trimming mode: paired-end
Trim Galore version: 0.6.4_dev
Cutadapt version: 2.10
Number of cores used for trimming: 1
Quality Phred score cutoff: 20
Quality encoding type selected: ASCII+33
Adapter sequence: 'CTGTCTCTTATA' (Nextera Transposase sequence; auto-detected)
Maximum trimming error rate: 0.1 (default)
Minimum required adapter overlap (stringency): 1 bp
Minimum required sequence length for both reads before a sequence pair gets removed: 20 bp
Running FastQC on the data once trimming has completed
Output file(s) will be GZIP compressed

Cutadapt seems to be fairly up-to-date (version 2.10). Setting -j -j 1
Writing final adapter and quality trimmed output to SPT5_T15_R1_T1_2_trimmed.fq.gz


  >>> Now performing quality (cutoff '-q 20') and adapter trimming in a single pass for the adapter sequence: 'CTGTCTCTTATA' from file SPT5_T15_R1_T1_2.fastq.gz <<< 
This is cutadapt 2.10 with Python 3.7.6
Command line parameters: -j 1 -e 0.1 -q 20 -O 1 -a CTGTCTCTTATA SPT5_T15_R1_T1_2.fastq.gz
Processing reads on 1 core in single-end mode ...
Finished in 4.37 s (44 us/read; 1.37 M reads/minute).

=== Summary ===

Total reads processed:                 100,000
Reads with adapters:                    42,703 (42.7%)
Reads written (passing filters):       100,000 (100.0%)

Total basepairs processed:     7,600,000 bp
Quality-trimmed:                  34,201 bp (0.5%)
Total written (filtered):      7,171,134 bp (94.4%)

=== Adapter 1 ===

Sequence: CTGTCTCTTATA; Type: regular 3'; Length: 12; Trimmed: 42703 times

No. of allowed errors:
0-9 bp: 0; 10-12 bp: 1

Bases preceding removed adapters:
  A: 19.8%
  C: 30.0%
  G: 24.1%
  T: 26.1%
  none/other: 0.0%

Overview of removed sequences
length	count	expect	max.err	error counts
1	18052	25000.0	0	18052
2	5381	6250.0	0	5381
3	1573	1562.5	0	1573
4	771	390.6	0	771
5	585	97.7	0	585
6	542	24.4	0	542
7	547	6.1	0	547
8	528	1.5	0	528
9	548	0.4	0	547 1
10	503	0.1	1	493 10
11	479	0.0	1	475 4
12	509	0.0	1	497 12
13	479	0.0	1	467 12
14	479	0.0	1	469 10
15	507	0.0	1	497 10
16	577	0.0	1	560 17
17	568	0.0	1	559 9
18	531	0.0	1	523 8
19	548	0.0	1	539 9
20	778	0.0	1	773 5
21	209	0.0	1	202 7
22	525	0.0	1	517 8
23	481	0.0	1	480 1
24	469	0.0	1	461 8
25	459	0.0	1	455 4
26	480	0.0	1	475 5
27	502	0.0	1	494 8
28	513	0.0	1	501 12
29	596	0.0	1	591 5
30	314	0.0	1	313 1
31	426	0.0	1	412 14
32	435	0.0	1	429 6
33	436	0.0	1	423 13
34	373	0.0	1	365 8
35	349	0.0	1	343 6
36	285	0.0	1	280 5
37	314	0.0	1	313 1
38	334	0.0	1	325 9
39	271	0.0	1	268 3
40	177	0.0	1	176 1
41	81	0.0	1	80 1
42	46	0.0	1	45 1
43	18	0.0	1	18
44	18	0.0	1	17 1
45	14	0.0	1	12 2
46	20	0.0	1	20
47	21	0.0	1	21
48	21	0.0	1	20 1
49	16	0.0	1	16
50	4	0.0	1	4
52	1	0.0	1	0 1
56	1	0.0	1	0 1
59	2	0.0	1	1 1
66	1	0.0	1	0 1
67	1	0.0	1	0 1
68	1	0.0	1	0 1
70	3	0.0	1	0 3
73	1	0.0	1	0 1

RUN STATISTICS FOR INPUT FILE: SPT5_T15_R1_T1_2.fastq.gz
=============================================
100000 sequences processed in total
The length threshold of paired-end sequences gets evaluated later on (in the validation step)

Validate paired-end files SPT5_T15_R1_T1_1_trimmed.fq.gz and SPT5_T15_R1_T1_2_trimmed.fq.gz
file_1: SPT5_T15_R1_T1_1_trimmed.fq.gz, file_2: SPT5_T15_R1_T1_2_trimmed.fq.gz


>>>>> Now validing the length of the 2 paired-end infiles: SPT5_T15_R1_T1_1_trimmed.fq.gz and SPT5_T15_R1_T1_2_trimmed.fq.gz <<<<<
Writing validated paired-end Read 1 reads to SPT5_T15_R1_T1_1_val_1.fq.gz
Writing validated paired-end Read 2 reads to SPT5_T15_R1_T1_2_val_2.fq.gz

Total number of sequences analysed: 100000

Number of sequence pairs removed because at least one read was shorter than the length cutoff (20 bp): 231 (0.23%)


  >>> Now running FastQC on the validated data SPT5_T15_R1_T1_1_val_1.fq.gz<<<

Started analysis of SPT5_T15_R1_T1_1_val_1.fq.gz
Approx 5% complete for SPT5_T15_R1_T1_1_val_1.fq.gz
Approx 10% complete for SPT5_T15_R1_T1_1_val_1.fq.gz
Approx 15% complete for SPT5_T15_R1_T1_1_val_1.fq.gz
Approx 20% complete for SPT5_T15_R1_T1_1_val_1.fq.gz
Approx 25% complete for SPT5_T15_R1_T1_1_val_1.fq.gz
Approx 30% complete for SPT5_T15_R1_T1_1_val_1.fq.gz
Approx 35% complete for SPT5_T15_R1_T1_1_val_1.fq.gz
Approx 40% complete for SPT5_T15_R1_T1_1_val_1.fq.gz
Approx 45% complete for SPT5_T15_R1_T1_1_val_1.fq.gz
Approx 50% complete for SPT5_T15_R1_T1_1_val_1.fq.gz
Approx 55% complete for SPT5_T15_R1_T1_1_val_1.fq.gz
Approx 60% complete for SPT5_T15_R1_T1_1_val_1.fq.gz
Approx 65% complete for SPT5_T15_R1_T1_1_val_1.fq.gz
Approx 70% complete for SPT5_T15_R1_T1_1_val_1.fq.gz
Approx 75% complete for SPT5_T15_R1_T1_1_val_1.fq.gz
Approx 80% complete for SPT5_T15_R1_T1_1_val_1.fq.gz
Approx 85% complete for SPT5_T15_R1_T1_1_val_1.fq.gz
Approx 90% complete for SPT5_T15_R1_T1_1_val_1.fq.gz
Approx 95% complete for SPT5_T15_R1_T1_1_val_1.fq.gz

  >>> Now running FastQC on the validated data SPT5_T15_R1_T1_2_val_2.fq.gz<<<

Started analysis of SPT5_T15_R1_T1_2_val_2.fq.gz
Approx 5% complete for SPT5_T15_R1_T1_2_val_2.fq.gz
Approx 10% complete for SPT5_T15_R1_T1_2_val_2.fq.gz
Approx 15% complete for SPT5_T15_R1_T1_2_val_2.fq.gz
Approx 20% complete for SPT5_T15_R1_T1_2_val_2.fq.gz
Approx 25% complete for SPT5_T15_R1_T1_2_val_2.fq.gz
Approx 30% complete for SPT5_T15_R1_T1_2_val_2.fq.gz
Approx 35% complete for SPT5_T15_R1_T1_2_val_2.fq.gz
Approx 40% complete for SPT5_T15_R1_T1_2_val_2.fq.gz
Approx 45% complete for SPT5_T15_R1_T1_2_val_2.fq.gz
Approx 50% complete for SPT5_T15_R1_T1_2_val_2.fq.gz
Approx 55% complete for SPT5_T15_R1_T1_2_val_2.fq.gz
Approx 60% complete for SPT5_T15_R1_T1_2_val_2.fq.gz
Approx 65% complete for SPT5_T15_R1_T1_2_val_2.fq.gz
Approx 70% complete for SPT5_T15_R1_T1_2_val_2.fq.gz
Approx 75% complete for SPT5_T15_R1_T1_2_val_2.fq.gz
Approx 80% complete for SPT5_T15_R1_T1_2_val_2.fq.gz
Approx 85% complete for SPT5_T15_R1_T1_2_val_2.fq.gz
Approx 90% complete for SPT5_T15_R1_T1_2_val_2.fq.gz
Approx 95% complete for SPT5_T15_R1_T1_2_val_2.fq.gz
Deleting both intermediate output files SPT5_T15_R1_T1_1_trimmed.fq.gz and SPT5_T15_R1_T1_2_trimmed.fq.gz

====================================================================================================

